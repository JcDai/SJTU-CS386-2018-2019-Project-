import torch
from torchvision import transforms
from torchvision.datasets import ImageFolder
import torch.utils.data as Data
from torch.autograd import Variable
import torch.nn as nn
import numpy as np
import torchvision.models as models


path = "E:\\train_data"

trans = transforms.Compose([transforms.Resize((224, 224)),
                            transforms.ToTensor()])

EPOCH = 1  # train data n times
BATCH_SIZE = 5
LR = 0.001

train_dataSet = ImageFolder("E:\\train_data", transform=trans)
test_dataSet = ImageFolder("E:\\test_data", transform=trans)
train_loader = Data.DataLoader(dataset=train_dataSet, batch_size=BATCH_SIZE, shuffle=True)
test_loader = Data.DataLoader(dataset=test_dataSet, batch_size=BATCH_SIZE, shuffle=True)


class CNN(torch.nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(
            nn.Conv2d(  # (3, 256, 256)     40, 40
                in_channels=3,
                out_channels=32,
                kernel_size=3,  # height and width of filter
                stride=1,
                padding=1,  # (kernel_size-1) / 2
            ),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),  # (32, 128, 128)
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(
                in_channels=32,
                out_channels=64,
                kernel_size=3,  # height and width of filter
                stride=1,
                padding=1,  # (kernel_size-1) / 2
            ),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),  # (64, 64, 64)
        )
        self.conv3 = nn.Sequential(
            nn.Conv2d(
                in_channels=64,
                out_channels=128,
                kernel_size=3,  # height and width of filter
                stride=1,
                padding=1,  # (kernel_size-1) / 2
            ),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2),  # (64, 64, 64)
        )
        # self.out = nn.Linear(64 * 64 * 64, 3)
        self.out = nn.Linear(128 * 5 * 5, 3)

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = x.view(x.size(0), -1)
        output = self.out(x)
        return output

cnn = CNN()
print(cnn)

optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)
# optimizer = torch.optim.SGD(cnn.parameters(), lr=LR)
loss_func = nn.CrossEntropyLoss()

for epoch in range(EPOCH):
    running_loss = 0
    for step, (x, y) in enumerate(train_loader):
        b_x = Variable(x)
        b_y = Variable(y)

        output = cnn(b_x)
        loss = loss_func(output, b_y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        running_loss += loss.data[0]

        if step % 10 == 9:
            print('[%d %5d] loss: %.3f' % (epoch + 1, step, running_loss / 10))
            running_loss = 0.0

correct = 0
top5correct = 0
total = 0
for data in test_loader:
    images, labels = data
    outputs = cnn(Variable(images))
    top5 = outputs.data.numpy()
    for idx in range(len(top5)):
        possible_answer = np.argpartition(-top5[idx], 2)[:2]
        for i in range(2):
            if possible_answer[i] == labels[idx]:
                top5correct += 1
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum()
    break

print('Accuracy of the network on the 30 test images: %d %%' % (100 * correct / total))
print('Accuracy of the network on the top5 images: %d %%' % (100 * top5correct / total))


